#+FILETAGS: REFULANG

* Language specification
** Interfaces
*** Specification
Refu relies heavily on the use of interfaces. Interfaces are an important
way to guarantee behaviour about objects. There are quite a few builtin
interfaces in the standard library. Here is one example which defines the
interface for the adding function. This allows an object to define how it
shall be added. One can notice the keyword =self= which defines the object
the function will be called for and also the generic syntax of <type T>
since we can't know the type of the object we are adding.

#+BEGIN_SRC C++
interface adder<type T> {
   fn(self:&T, other:c:~T) -> T
}
//An implementation would declare that it implements the adder interface like below
vec_adder implof adder for vector {
   fn(self, other:c:~vector) -> vector
   {
       ret:vector
       ret.x = self.x + other.x
       ret.y = self.y + other.y
       ret.z = self.z + other.z
       return z
   }
}
#+END_SRC

An important thing about interfaces is that data types can implement EACH
and every single interface in a different place in the code.
Rationale: Picture you buy the code from someone and you can't change the
implementation and have only the headers and you need to implement some
extra interfaces without changing the original code.

Another additional concern is on cases where you may want to have a
different implementation of an interface changed and swapped even in
runtime. Imagine that there is this interface called 'Ordering'
which denotes how the members of something should be ordered.
Then we have two implementation of this interface, both implemented by a
data type, say a list. One implements an ascending order ordering and the
other a descending order ordering. There should be a way to choose in
runtime which of the two implementations the ordering would use.

So let's look at the following example, which will not compile.
#+BEGIN_SRC C++
ord_ascend implof ordering for vector {
    fn(self)
    {
        ...
    }
}

ord_descend implof ordering for vector {
    fn(self)
    {
        ...
    }
}
#+END_SRC

Why will this not compile? Well simply because 2 different implementations
of an interface are declared for a type without specifying one as the
default implementation for all objects of type vector.
#+BEGIN_SRC C++
ord_ascend dimplof ordering for vector {
    fn(self)
    {
        ...
    }
}

ord_descend implof ordering for vector {
    fn(self)
    {
        ...
    }
}
#+END_SRC

With the above code we can declare the =ord_ascend= implementation as
default and as such all vector types unless otherwisespecified will have
this implementation for the ordering interface


#+BEGIN_SRC C++
a:list // ord_ascend
b:list<ordering: ord_ascend> // ord_ascend
c:list<ordering: ord_descend> //ord_descend
#+END_SRC

*** Thoughts
** Error Handling
*** Specification
(Nice info about [[http://en.wikibooks.org/wiki/Computer_Programming/Error_handling][error handling]] in general and [[http://en.wikibooks.org/wiki/Computer_Programming/Design_by_Contract][Design by contract]] )
Error handling is a very serious topic. Refu attempts to make it easy for
the developer to handle all erroneous conditions with ease without
cluttering the implementation of functions. We aim to make it easy to
handle errors and we assume that the execution path in case of an error
is not performance critical since errors are and should always be
extraneous situations.
(Just like they mention in the [[http://dlang.org/errors.html][D language error page]])

There are multiple ways to actually handle errors in a function and we
will present them here.

- Exceptions
  Exceptions can be raised at any point during the code and the stack
  will unwind, calling the deallocators of all objects it encounters
  until a catch is hit.

  #+BEGIN_SRC C++
  exceptions {
  negative_double_in_sqrt
  some_other_exception ...
  }
  fn calculate_square_root(a:double) -> double
  {
      if (a < 0.0) {
           raise // this would raise a generic anonymous exception
           raise negative_double_in_sqrt("Omg noez") // raise a specific exception
      }
      return a*a
   }


   ....
   ....

   try {
       ...
       calculate_square_root(-1.0)

   } catch (e){
       negative_double_in_sqrt =>  do something
       print(e.str)
       _ => {
           print(e.error_str) //the message of the raise
           print(e.location_str) //the location of the raise (function, line_no, file)
       }
}
#+END_SRC

Exceptions can also be part of an exception class. There are some
built-in exception classes defined in the standard library
like std::exceptions::memory, std.exceptions.io and
std::exceptions::numeric. To define an exception as a member of an
exception class the following syntax is used:

exception negative_double_in_sqrt partof std::exceptions::numeric
exceptions {
     negative_double_in_sqrt partof std::exceptions::numeric
     some_other_exception ...
}

- Design By Contract
  A function can have a contract with its caller. Such contracts are made up
  of calling preconditions and calling postconditions. If possible these
  checks are performed in compile time, and compiled away for the runtime.
  If not they raise an exception in runtime. The user has the option to
  completely disable them for a release build.
  (Have to think if this should actually happen)
#+BEGIN_SRC C++
calculate_square_root(a:double) -> double
precond(a >= 0.0)
postcond(result >= 0.0) //not needed, but just here as an example
{
    return a*a;
}
#+END_SRC
*** Thoughts
** Modules
*** Specification
Programs and libraries written in Refu are divided in modules. A module
can be imported from other parts of code as is, like:
#+BEGIN_SRC C++
import geometry
#+END_SRC

Certain functions, structs or data from modules can also be imported
alone so that the global namespace is not polluted.
#+BEGIN_SRC C++
import vector3d, model from geometry
#+END_SRC

Additionally, imported objects can be given an alias so as to avoid
name conflicts

#+BEGIN_SRC C++
import vector3d, model from geometry as vector_imp, model_imp
#+END_SRC


To encapsulate code into a module one would need to enclose it in
a module block like so:

#+BEGIN_SRC C++
module geometry{
...
...
...
}
#+END_SRC


Modules encompass functionality. In order to allow separation between
private and public module objects there are 2 different ways to arrange
modules. One is as shown above, having all of the module related code
encompassed in a identifier module { ... } block. In that case everything
would be private in the module by default. To mark something as public and
exportable to other modules then you would have to prepend it with the
=export= keyword.

#+BEGIN_SRC C++
module geometry{

    struct private_foo{
    ...
    }

    //model will be exported since it has the export attribute
    export struct model{
    }

    //this function will be visible from outside the module
    export fn some_public_function(..) ->foo
    {
    }

    //this function will not be visible from outside the module
    fn private_function(..) -> foo
    {
    }

}//end of module
#+END_SRC

Another way to organize modules and by far the preferred way is to
separate a module's signature from its implementation. This allows for
separation of interface from implementation, module typechecking, cleaner
code look and most importantly multiple implementation of module code for
different systems.

As an example consider an IO module that implements I/O functionality for
Linux, Windows, ARM or even javascript!

#+BEGIN_SRC C++
signature io {
    data file; /* definition is in module implementation */

    fn open(name:~string) -> ~file
    fn read(f:~file) -> ~bytes
    fn write(f:~file, b:~bytes) -> int
}
#+END_SRC

and in two other separate files, the module implementation could be like
this for a different windows and linux implementation.
#+BEGIN_SRC C++
linux_io implof io {
    data file {
        ...
    }

    fn open(name:~string) -> ~file
    {
        ...
    }
    fn read(f:~file) -> ~bytes
    {
        ...
    }
    fn write(f:~file, b:~bytes) -> int
    {
        ...
    }
}
#+END_SRC

#+BEGIN_SRC C++
windows_io implof io {
    data file {
        ...
    }

    fn open(name:~string) -> ~file
    {
        ...
    }
    fn read(f:~file) -> ~bytes
    {
        ...
    }
    fn write(f:~file, b:~bytes) -> int
    {
        ...
    }
}
#+END_SRC
Anything not in the signature of a module is going to be private to a
particular module implementation.

Modules can also accept arguments. Irrespective of the way you declare a
module it can always accept arguments.
- *Signature*
   #+BEGIN_SRC C++
   signature test_module(g:geometry, buffer_size:int = 512) {

       fn do_something()
       fn do_something_with_geometry(t:g::triangle)
       ...

   }

   test implof test_module(g:geometry, buffer_size:int) {
       import g //import the module we passed as argument

       do_something()
       {
           allocate_buffer(buffer_size)
       }

       do_something_with_geometry(t:g::triangle) -> f32
       {
           return g::calculate_area_of_triangle(t)
       }

   }
   #+END_SRC

- *Without Signature*

  #+BEGIN_SRC C++
  module test_module(g:geometry, buffer_size:int = 512) {
      import g //import the module we passed as argument

       export do_something()
       {
           allocate_buffer(buffer_size)
       }

       export do_something_with_geometry(t:g::triangle) -> f32
       {
           return g::calculate_area_of_triangle(t)
       }
   }
  #+END_SRC

In order to import this from some other place in the code you would do
something like the following:
#+BEGIN_SRC C++
import some_module(my_geometry, 1024)
#+END_SRC

*** Thoughts
Where should the modules be searched for? How should linking other libraries
work?
** Parallel Processing Framework / Parallel Routines
*** Specification
In Refu many small lightweight threads can be spawned. They are called
routines and can be created with the rt keyword.
For example:

#+BEGIN_SRC C++
fn print_some_stuff()
{
   print("eleos")
   print("lol"
}
//run print_some_stuff in another thread
rt print_some_stuff
#+END_SRC

Routines can be communicated to via message passing. ...
More thinking to go here ...TODO
*** Thoughts
** Built-in data types
*** Specification
The following data types are built-in. Some of them correspond to the data types
defined by the C99 standard in =<stdint.h>= but they follow the same naming
scheme as in rust.

- *Unsigned numbers*
  + =u8=: 8 bit unsigned integer, corresponding to =uint8_t=
  + =u16=: 16 bit unsigned integer, corresponding to =uint16_t=
  + =u32=: 32 bit unsigned integer, corresponding to =uint32_t=
  + =u64=: 64 bit unsigned integer, corresponding to =uint64_t=

- *Signed numbers*
  + =i8=: 8 bit signed integer, corresponding to =int8_t=
  + =i16=: 16 bit signed integer, corresponding to =int16_t=
  + =i32=: 32 bit signed integer, corresponding to =int32_t=
  + =i64=: 64 bit signed integer, corresponding to =int64_t=

- *Real numbers*
  + =f32=: corresponds to binary32, single precision floating point, as
    defined by [[http://en.wikipedia.org/wiki/IEEE_754-2008][IEE 754-2008]]
  + =f64=: corresponds to binary64, double precision floating point, as
    defined by [[http://en.wikipedia.org/wiki/IEEE_754-2008][IEE 754-2008]]

- *Strings*
  + =string=: UTF-8 encoded unicode string.
  + =string8=: Ascii encoded string

- *Other*
  + =bool=: A boolean true or false value
  + =nil=: the unit type, also known as NULL
*** Thoughts
Maybe add f16 and f128 in the future?
** Algebraic Data Types
*** Specification
More complex data types can be defined as Algrebraic data types. This is
achieved with the =data= keyword.

#+BEGIN_SRC C++
data person {
    name:string ,age:int |
    name:string, age:int, surname:string
}
data list {
     nil | (load:int, tail:~list)
}

data foo {
a:int,
b:(string|float)
}

data foo {
a:int,
b:(string | (i:int, f:float))
}
#+END_SRC

Above we have the definition of a person and a list. A person has a name
and an age and optionally a surname. And a list is either empty (denoted
by the =nil= keyword or it has a load of an int and a tail which is another
list.

In order to construct an instance of a data type you have to use one of its
constructors. A constructor of an object is simply defined as any of its 
sum type operands.
#+NAME Constructing an instance of a data type
#+BEGIN_SRC C++
a:person = person("steven", 23)
b:person = person("celina", 22, "wojtowicz")
#+END_SRC

As can be seen below for ease of use arguments can also be given to a
constructor as keyword arguments. If one keyword argument is passed to a
constructor then all arguments should be keyword arguments. Finally when
passing keyword arguments the order of the arguments does not matter as 
opposed to when calling a constructor normally.

#+NAME: Constructing an instance of a data type with keyword arguments
#+BEGIN_SRC C++
a:person = person(name="steven", age=23)
b:person = person(name="celina", surname="wojtowicz", age=23)
#+END_SRC

As we saw in the very beginning data types can also be recursive. This is
how we can define collections in Refu. But how do you construct a collection?
#+NAME: Constructing an instance of a recursive data type
#+BEGIN_SRC C++
a:list = nil
b:list = list(1, 2, 3, 4, 5)
c:list = list(1, list( 2, list(3, list(4, list(5, nil)))))
#+END_SRC

In the above examples list =b= and list =c= are equal. The canonical way to
define a list would be exactly like list =c= is defined, having /1/ as its
first element and using nil after /5/ to denote the list's end.

As we can see above to construct a recursive data type we still use a 
constructor but we can take advantage of the fact that the type is recursive
in order to construct it.

In the case of =b='s construction Refu knows that a list's constructor can
only accept an int and a next list pointer. Using that knowledge it can 
expand the =list(1, 2, 3, 4, 5)= to =list(1, list(2, list(3, list(4, list(5, nil)))))=.

Same thing can work for more complex recursive data types such as a binary
tree. Look below for an example.
#+BEGIN_SRC C++
data binary_tree {
nil | load:int, left:~binary_tree, right:~binary_tree
}

a:binary_tree = nil
b:binary_tree = binary_tree(8, (4, (1, 7)), (12, (10, 19)))
c:binary_tree = binary_tree(
    8, 
    binary_tree(4, 
                    binary_tree(1, nil, nil), binary_tree(7, nil, nil)),
    binary_tree(12, 
                    binary_tree(10, nil, nil), binary_tree(19, nil, nil)))
#+END_SRC

From both the binary tree and the list example we can see that Refu tries
to interpret a pointer to an object as =nil= if not existing.

An algebraic data type can be considered as the equivalent of a
tagged union type in C. Refu also supports anonymous ADTs. That means,
you can encounter the ADT syntax without it having been defined.
For example, a function's argument can be an anonymous ADT.

#+NAME: Example 1
#+BEGIN_SRC C++
fn print_me(a:(string|b:int, c:int))
{
    //do some initialization stuff
    ...
    //and now do the pattern matching
    match(a) {
        (string) => print("%s", a)
        (int, int) => print("%d %d", a.b, a.c)
    }
}
#+END_SRC

#+NAME: Example 2
#+BEGIN_SRC C++
fn print_me(a:string | (b:int, c:int)) -> int
(_) => print("%s", a)
(_, _) => print("%d %d", b, c)
#+END_SRC

#+NAME: Example 3
#+BEGIN_SRC C++
fn print_me(a:string | (b:int, c:int)) -> int
(_) => {
    print("%s", a)
    print("one argument")
}
(_, _) => {
    print("%d %d", b, c)
    print("two arguments")
}
#+END_SRC

In all of the above examples we have one function with an anomymous ADT.
If such a  function exists then it must have a match expression somewhere
inside its body in order to distinguish what kind of input it is having
before this input is used. The most explicit way to achieve this is to
write the match expression explicitly as in example 1. To do that we match
the keyword fn inside the function's body against the various cases.

In another case if the function body consists only of different branches
depending on the input we can omit the function's body block completely
and go with the way that example 2 is defined, which resembles a lot the
way functions are defined in haskell. It is just syntactic sugar for
achieving the same thing as in example 1. Example 3 is just an extended
version of example 2 in which each branch of the match has many statements
to execute.
*** Recursive ADTs considerations
Recursive data types such as the list or the binary_tree presented above
can be quite complicated but when the compiler takes mutability into account
many optimizations can be performed especially for a very simple data structure
with only one link like the list.

#+BEGIN_SRC C++
{
    a:list = list(1, 2, 3, 4)// this is an immutable list
    b:mut ~list = list(1, 2, 3, 4)//mutable list on the heap
}
#+END_SRC

In the above example list =a= is immutable and is allocated on the stack. As 
such the compiler can apply the following optimization to it.
#+BEGIN_SRC ditaa
/------------+
|      1     |
+------------|
|      2     |
+------------+
|      3     |
+------------|
|      4     |
+------------|
|     nil    |
+------------/
#+END_SRC
You can notice that since it's immutable and since it has only one recursion 
path it can be optimized by the compiler to be a simple array.

If on the other hand it's a mutable list like =b= then no such optimization
can be performed and it would look like this in memory:
#+BEGIN_SRC ditaa
/------------+
|      1     |
+------------|
|     next   |--+
+------------|  |
|      2     |<-+
+------------+
|     next   |--+
+------------|  |
|      3     |<-+
+------------|
|     next   |--+
+------------|  |
|      4     |<-+
+------------|
|      next  |---> nil
+------------/
#+END_SRC

Same thing could apply if we had a binary_tree data_structure but the
optimization would work only in some cases. In other cases where the
tree is not balanced and there are many leaves it would make no sense to 
try and so such a thing. This is thought in progress.

*** Thoughts
Everything should be a type defined on top of other types. This should
mimick haskell but I would like to find a nice syntax for it. I really
like the short explanation of [[http://blog.lab49.com/archives/3011][this]] blog post and could go with similar
syntax but am afraid it may become complicated. That is why I need to
think of some syntactic sugar to make it more presentable.
A feature request from steffen that he claims Haskell and other functional
languages lack is that of anonymoys types. For example in those languages
we can't have a function like =do_something(int + string)=. You would have to
define that as a separate type. In Refu we should be able to have anonymous
types like this.

Another type related feature request from Steffen is that he would like,
as a programmer, to be able to define functions that act on types and
return other types. For example a type function called vectorize that
takes a type and returns another type which is a vectorized version of
the original. Like data simple = string + int and vectorize simple would
return [string] + [int]

A very interesting [[http://paulkoerbitz.de/posts/Understanding-Pointers-Ownership-and-Lifetimes-in-Rust.html][article]] about pointers, ownership and lifetime of objects
in Rust.

Another very interesting article about types of data is [[http://tel.github.io/2014/07/23/types_of_data/][here]]. A more complete guide to 
the algebra of the algebraic data types is here. ([[http://chris-taylor.github.io/blog/2013/02/10/the-algebra-of-algebraic-data-types/][Part 1]], [[http://chris-taylor.github.io/blog/2013/02/11/the-algebra-of-algebraic-data-types-part-ii/][Part2]], [[http://chris-taylor.github.io/blog/2013/02/13/the-algebra-of-algebraic-data-types-part-iii/][Part 3]])
*** Implementation considerations
This ADT declaration for a list in refu (data list = 1 + int*list)
#+BEGIN_SRC C++
data list{
    nil | a:int, next:~list
}
#+END_SRC

Would generate one of the following codes in C:
#+NAME Method 1
#+BEGIN_SRC C
struct list {
      enum tag { NULL, int_by_list};
      union {
             struct {} NULL; //(whatever way that would be represented
             struct {
               int 1;
               list *2; //(whatever way that would be represented
            }
    };
};

#+END_SRC

#+NAME Method 2
#+BEGIN_SRC C
enum list_tag { LIST_TAG_NULL, LIST_TAG_CONS }
struct list {
    list_tag tag;
}
struct list_NULL {
    list type;  // type.tag = LIST_TAG_NULL
}
list_NULL list_NULL_singleton = { LIST_TAG_NULL }
struct list_CONS {
    list type; // type.tag = LIST_TAG_CONS
    int 1;
    list *2;
}
const list *constructor_list_NULL(void) {
    return (list*)&list_NULL_singleton;
}
/*
A note about the malloc here. Any kind of memory allocation scheme could and should be used.
For example there could be something like cons_alloc which would simply take blocks of conses
with different CAR size but same (pointer size) CDR
*/
const list *constructor_list_CONS(int i, list *next) {
     list_CONS *cons = malloc(...);
     cons.type.tag = LIST_TAG_CONS;
     cons.1 = i
    cons.2 = next
    return (const list*)cons;
}
bool is_NULL(list *l)
{
     return l->type.tag == LIST_TAG_NULL;
}
bool is_CONS(list *l)
{
     return l->type.tag == LIST_TAG_CONS;
}
#+END_SRC

And as an example of a function using ADTs think of this.
#+BEGIN_SRC C++
fn len(a:list) -> int {
    len NULL = 0
    len CONS(_, rest) = 1 + len(rest)
}
#+END_SRC

This would generate the following in C.

#+BEGIN_SRC C
int len(list *l)
{
     if (l->type.tag == LIST_TAG_NULL) { return 0; }
     else {
          list *rest = ((list_CONS*)l)->2;
          return 1 + len(rest);
     }
}
#+END_SRC

** Memory Model
*** Specification
The memory model of Refu is very similar to that of the Rust programming
language. All non-pointer objects are allocated on the stack and are freed
when they go out of scope. This is much like most other languages out there.
For example:
#+BEGIN_SRC C++
{
    a:int
    s:string
} //memory for both will be released here
#+END_SRC

To allocate memory in the heap a pointer type is used. If a pointer type gets
declared in a scope it has to be initialized. This way we can avoid dangling
pointers.

**** Unique pointers
A unique pointer, just like in Rust is represented by the =~= symbol.
For example
#+BEGIN_SRC C++
data person {
    name:string,
    age:int
}

fn main()
{
    a:person = person("jerry", 22)
    b:~person = person("john", 15)
    c:~person = b
    // from here and on b can't be used
}
#+END_SRC

A unique pointer is also known as an /owned pointer/. What this means is
that the pointer is owned by the scope it is in. As an example at the above
code =b= is initialized and acquires ownership of John. Then =c= takes
ownership of john by the assignment.

Any use of b afterwards would be invalid and would raise a compiler error.

An owned pointer can also appear inside a data definition. If that happens
then that means that objects of the data type own the object to which they
contain an owned pointer. 
#+BEGIN_SRC C++
data file_index {
    nil | index:~something
}
data person {
    name:string,
    age:int,
    index:~file_index
}

fn set_something(p:&person, i:~file_index)
{
    p.index = file_index
}

fn main()
{
    i:file_index = something(...)
    a:person = person("jerry", 23, nil)
    b:~person = person("tom", 52, nil)
    
    set_something(b, &i);
    //from here and on i is owned by b and can't be assigned to anything
    
    c:~person = b
    //from here and on b can't be accessed
    d:person = a //illegal!
}
#+END_SRC

Noteworthy from above is how we can denote that a pointer can be pointing
to a speciall value that means empty as we can see from the definition of
the =file_index= object.

Another thing to note is the assignment of the object owned by =b= to =c=.
Since they are both owned pointers of an object the assignment operation
simply moves the ownership of the pointer and as such =b= can't be accessed
anymore.

Finally an interesting thing to note about data structures that are owners
of data is that they can't simply be assigned. The person in the above example
is one such data structure. By attempting to assign =a= to =d= which would be
a copy operation we are performing an illegal operation since that would also
create a second instance of the owned pointer inside ~a:person~.


**** Shared pointers
Probably should be only in the std::lib and should offer different management
strategy, like garbage collection or reference counting.

**** References


*** Thoughts
What about shared and weak pointers? Check all C++ 11 pointer types and
think of equivalents. Also think about mutability. Should everything be
immutable by default? And make them mutable with a keyword or other
syntactic construct or should it be the other way around?

- *Pointer Types*
Here is [[http://static.rust-lang.org/doc/master/rust.html#pointer-types][rust's pointer types page]] and a nice [[http://pcwalton.github.io/blog/2013/03/18/an-overview-of-memory-management-in-rust/][blog post]].
- *Shared pointers*
   [[http://pcwalton.github.io/blog/2013/06/02/removing-garbage-collection-from-the-rust-language/][Why]] shared pointers are removed from Rust core language and moved to std lib

** Functions
*** Specification
Functions in Refu are declared just like in the Rust language. The
keyword =fn= followed by the name of the function, the arguments and
finally by an arrow pointing to the return value.  If there is no return
value then the arrow is omitted. Some examples follow:

#+BEGIN_SRC C++
fn add_two_ints(a:int, b:int) -> int
{
     return a + b
}

fn print_something()
{
     print("something")
}
#+END_SRC

Inside the function's body a =return= statement denotes the expression
that determines the return value. A function may return a value but still
need no return value if it's compact enough and has all its
functionality under a =match=, =if= or =for= expression. For example:

#+BEGIN_SRC C++
fn find_length(a:~list)->int
(nil) => 0
(_, tail) => 1 + find_length(tail)

fn int_inside_range(x:int, from:int, to:int) -> bool
{
    if (x >= from && x <= to) { true} else { false}
}
#+END_SRC
** Array types
*** Specification
Array types are like simple C arrays that are aware of their own size so as to
make sure there is no out of bounds access. An array is simply a contiguous 
block of memory containing values of the same type.
#+BEGIN_SRC C++
array_of_ints:int[20]
array_of_strings:string[20]
a:int = array_of_ints[5]
b:int = array_of_ints[22] //run-time error
#+END_SRC

Dynamic size arrays can also be instantiated with the built-in =alloc()=
function. An array's size in elements can be queried by =array.size=.

#+BEGIN_SRC C++
fn foo(b:&u8[]) {
    buffer1:u8[] = b;
}

buffer:u8[] = alloc(10)
foo(buffer)
printf("%d", buffer.size); // should print 10
#+END_SRC

Array types are also closely related to the way the memory model of the
language works and to how a buffer can be initialized.

#+BEGIN_SRC C++
struct parser {
    something:int
    buffer:~byte
    string_buffer:~string
}
parser_alloc implof std::allocator for parser {
        fn(self, a:int)
        {
           self.something = a
           self.buffer = balloc(NUMBER_OF_BYTES_TO_MALLOC)
           self.string_buffer = balloc(NUMBER_OF_STRINGS_TO_MALLOC)
        }
}
// later they can both be accessed like normal arrays
p:parser
...
...
character = p.buffer[20]
a_string = p.string_buffer[2] //the size is checked in runtime and if there is an out of bounds access attempt an error is raised
#+END_SRC

Note that even though the notation of the buffers is using (~) just like
all the other unique pointers, memory not only for one string or one byte
is allocated but since the built in balloc (buffer_alloc) function is
used, they are pointers to buffer arrays. Also note that at some point
the buffers can be reallocated with brealloc.
brealloc(p.buffer, 100)

Those buffers will be freed when the containing struct gets freed.

*** Thoughts
Thinking if the language should have arrays, maybe some form of
lists e.t.c. A nice analysis can be seen [[http://pcwalton.github.io/blog/2012/12/28/a-tour-of-vectors/][here]]
** Generics
*** Specification
Refu supports generics, which allow a user to define a generic data type
and then use it with different concrete types, just like in C++ templates.
For example:

#+BEGIN_SRC C++
data list<type T>{
     Nil | payload:T , tail:~list
}
..
..

a:list<int> = (5, 6, 7, 8)
//the above would be a shortcut for cons(Nil, cons(5, cons(6, cons(7, cons(8, Nil) ) ) ) )
#+END_SRC

This would define a generic ADT list, and later the user declares a list
of ints and populates it. Same thing can be done with an ADT binary tree.

#+BEGIN_SRC C++
data binary_tree <type T> {
    Nil | payload:T , left_branch:~binary_tree, right_branch:~binary_tree
}
...
...
/*
             1.0
             / \
         0.1    2.0
         /  \    / \
      0.01 0.2  1.5 3.3
*/

a:binary_tree<double> = ( 1.0, (0.1, (0.01), (0.2))),  (2.0, (1.5, 3.3)))
a:binary_tree<double> = (1.0, cons(0.1, cons(0.01, Nil), cons(0.2, Nil) ),  cons(2.0, cons(1.5, Nil), cons(3.3, Nil)))
#+END_SRC

Generics can also apply to structures and functions like we can see below.
Also we can have more than one generic type at a given time.

#+BEGIN_SRC C++
struct person<type T, type Y> {
    budget: T
    name: string
    places_visited:list<Y>
}

fn populate_budget<type T, type Y>(a:person<T,Y>, budget:T)
{
   person.budget = budget
}
#+END_SRC

** Pattern matching
*** Specification
Algebraic data types go hand in hand with the ability to use pattern
matching on those types. This is offered by the match expression keyword
in refu.

Pattern matching is the elimination construct for algebraic data types.
That means that a pattern matching expression, expresses how one should
consume a partciular ADT. For example look below.

#+BEGIN_SRC C++
data list {
nil | member:int,rest:~list
}
a:list
match a {
     (nil) => print("empty list")
     (i, _) => print("Head of the list is %d", i)
}
#+END_SRC

Match expressions can also be recursive. A =match()= inside a match expression
renders the whole match recursive. For example look at the matching below
which calculates the length of a list.

#+BEGIN_SRC C++
fn find_length(a:~list)->int
{
    return match a {
        (nil) => 0
        (_, tail) => 1 + match(tail)
    }
}
#+END_SRC
For completeness sake it should be noted that the above example can
be written in a simpler way, having the function block omitted:

#+BEGIN_SRC C++
fn find_length(a:c:~list)->int
(nil) => 0(_, tail) => 1 + find_length(tail)
#+END_SRC

In a =match=, all possible value combinations must be exhausted. =_= means
any value, =nil= means no value and anything else is interpreted as an
identifier to recognize that particular positional argument. Another way
to match something would be depending on the type. For example.

#+BEGIN_SRC C++
data list<T> {
nil | (load:T, tail:~list)
}

a:list<int>
list_type:string = match a {
   (nil) => "empty list"
   (int, _) => "list of ints"
   _ => "other kind of list"
}
#+END_SRC

From the above, one can notice the following. A match expression is just
that, an expression and can as easily be assigned to something. Also a
match can be on some type with the built-in keyword =typeof=. Finally it
is a compile error to not exhaust all possible matches, so the _ at the
end matches all other cases.

*** Thoughts
As very nicely stated on [[http://stackoverflow.com/a/2226292/110395][this SO answer]], pattern matching is the elimination
construct for algebraic data types. That means that a pattern matching
expression, expresses how one should consume a partciular ADT.
** If expressions
*** Specification
In Refu an if can act either as an expression or like a statement
depending on the context. That means, that you can assign an if
expression as values to variables. The general if syntax is as follows:

#+BEGIN_SRC C++
if i > 10 {
    increase_a_value()
    compress_a_file()
} elif i < 0 {
    do_something_else()
} else {
    do_last_thing()
}
#+END_SRC

The above =if= acts as a statement since it is not in the right side of
any kind of assignment. But observe below another example usage where =if=
is used as an expression. Depending on the value of =i=, we assign a
specific value to =a=.

#+BEGIN_SRC C++
a:m:int
a = if i > 10 {
        20
} elif i < 0 {
        40
} else {
        100
}
#+END_SRC

A more advanced usage of an if expression can also be seen below. A data
type of two void functions with no arguments is defined. Then a variable
of that type is declared.

#+BEGIN_SRC C++
data two_functions {
   fn(), fn()
}

functions_caller:two_functions
funcions_caller = if i  > 10 {
         do_something_good()
         do_something_good2()
} elif i < 0 {
        do_something_mediocre()
        do_something_mediocre2()
} else {
        do_something_bad()
        do_something_bad2()
}
...
...
//later f can actually be called somewhere
functions_caller
#+END_SRC

Unlike some other languages the curly braces can't be omitted in any
branch of the if. If the condition of an if branch is complex enough then
it should be enclosed in parentheses like so:

#+BEGIN_SRC C++
if ( (i > 10 && i <20) || (x > 30 && x < 40)) {
      do_something()
}
#+END_SRC
** For expressions
*** Specification
The simplest way to iterate something in refu is by using a for
expression. The syntax is simple. For a simple iteration of n times one
can use the following.

#+BEGIN_SRC C++
for i in [0..10] {
      do_something(); //this will iterate 11 times, with i ranging from 0 to 10
}
#+END_SRC

There are many ranges that can be covered by a simple for expression.
The simple iteration syntax is =for= /identifier/ =in= /range/. Where
range is a numeric expression within braces of the form
[start .. step .. end].
The step is optional and is shown in the next example.

#+BEGIN_SRC C++
for i in [0..2..10] {
     print(i); //this will print 0, 2, 4, 6, 8, 10
}
#+END_SRC

For expressions are also heavily customizeable on a per type basis.
By implementing the standard library's iterator interface you can define
how the expression behave for a specific data type. For example:

#+BEGIN_SRC C++
data list {
Nil |
payload:int, tail:~list
}

list_iter implof std::iterator for list {
    fn(self)->list
    {
        match(self) {
         (Nil) => return Nil
         (val, tail) => return (val, tail)
        }
    }
}

my_list:list = (1, 2, 3, 4, 5)
for i in my_list {
     print(i) //this should print all the values of the list.
}
#+END_SRC

By defining the =list_iter= implementation of the iterator interface we
just defined the way that lists can be iterated. Afterwards whenever a for
expression is used on a list, the defined implementation is used.
The iterator interface looks like this:

#+BEGIN_SRC C++
interface iterator <T>{
     fn(self:&self_type) -> (Nil | (T, ~self_type))
}
#+END_SRC

So, all implementations need to do is define the value at each iteration,
the next object of the iteration and the condition under which the
iteration terminates. The function must return either Nil to denote the
end of the iteration, or a value of type T and the next object for
iteration.

But if you recall the title of the section is for *expressions*. As expressions
they can also be assigned. For example an array can be assigned like this:

#+BEGIN_SRC C++
arr:int[3] = [5, 6, 7]
another_arr:int[] = for i in arr { i + 3}
#+END_SRC

Afterwards =another_arr= will contain [8, 9, 10]. Of course these
expressions are checked at compile time for validity of type assignment.
If the for block had something that is not an int, or if it had more
statements then it would be a compile error. On the left hand of the
assignment any identifier whose type would agree with (Nil | int, T) would
be acceptable.
** Mutability
*** Specification
All data are by default immutable in Refu. In order to specify mutability
or not of a data type this is done in the type declaration. For example:

#+BEGIN_SRC C++
struct person {
    age:int
    name:string
}
#+END_SRC

Would create an immutable person type. Once an instance of this type is
initialized it would not be allowed to change.

#+BEGIN_SRC C++
fn change_a_person(p:&person)
{
    p.age = 1
}
steve:person = ("steve", 25)
change_a_person(steve) /* not allowed*/
#+END_SRC C++

The above would not work since steve is declared as a mutable person. To
overcome this problem we would need to do one of two things.

#+NAME Method 1
#+BEGIN_SRC C++
mut struct person {
    age:int
    name:string
}

fn change_a_person(p:&person)
{
    p.age = 1
}
steve:person = ("steve", 25)
change_a_person(steve)
#+END_SRC
In the above example we simply define a mutable type and as such the example
works fine.

But if on the other hand we wanted to keep the immutable person type we could
simply modify the function to return a copy.
#+NAME Method 2
#+BEGIN_SRC C++
fn change_a_person(p:&person) -> ~person
{
    res:person = (p.name, p.age)
    return res;
}
#+END_SRC

*** Thoughts
The question of immutability is a very interesting one. There are many
examples to be drawn from Scala. [[http://www.scala-lang.org/docu/files/collections-api/collections_12.html][Here]] is a list of mutable and immutable
collections in scala.

Also [[http://docs.scala-lang.org/overviews/collections/overview.html][here]] is a nice piece on the scala docs outlining main differences
on usage of mutable and immutable collections.
* Features to experiment with
** Type system - Dependent types
[[http://ejenk.com/blog/why-dependently-typed-programming-will-one-day-rock-your-world.html][Interesting blog post]]
Read about: dependent types, currying

The language's type system is a very controversial matter but one that does
require a lot of thinking.

There should be a way to allow for types of functions to be included into
the type system so that we can accomodate higher order functions. A syntax
I can imagine for it is like the following:
#+BEGIN_SRC C++
data my_type {
a -> (b, c) -> d
};
#+END_SRC

A function that could be of this type is the following:

#+BEGIN_SRC C++
foo(a) {
      .....
  return function(b, c) {
        return a + b + c;
  }
}
#+END_SRC

or in other notation
#+BEGIN_SRC C++
func foo (a:A)->(b:B, c:C) -> D {
   return a + b +c;
}
#+END_SRC


(note: in Haskell, ML a function's arguments are separated by -> .. so the
below as originally written by steffen was)
#+BEGIN_SRC haskell
x:string -> print_types(x) -> void
#+END_SRC

Stephen mentioned that with dependent types you can have functions that are
all just executed in compile time since they are only used in type
checking. This, he said can end up being quite a bit complicated.

In which case print_types(x) would be a compile time function implemented
like:

As an example he said to think of the printf function.
printf is of type:     x:string, print_types(x) -> void

#+BEGIN_SRC C++
print_types(x) {

    match(x)
             '%d' => int, print_types(rest(x))
             '%s' => string,print_types(rest(x))
              ....
            else: print_types(rest(x))
    }
}
#+END_SRC

and running this compile time function to determine the type of
=printf("eleos %s lol %d")= would give us
=x:string, string, int, -> void=
** Variadic generics
When I delve more into how generics work in Refu then think if it would be
possible and beneficial to introduce variadic generics, so that we have
functions with variadic number of arguments of known types.
C++11 can do it: http://stackoverflow.com/questions/10044449/a-function-with-variable-number-of-arguments-with-known-types-the-c11-way
** Type inference
When I delve more into how generics work in Refu then think if it would be possible and beneficial to introduce variadic generics, so that we have functions with variadic number of arguments of known types.
C++11 can do it: http://stackoverflow.com/questions/10044449/a-function-with-variable-number-of-arguments-with-known-types-the-c11-way
* Runtime implementation
** Some thoughts
As far as the runtime is concerned I believe I should have a memory
allocation scheme for all of the recursive data structures. The way I have
thought it up is having preallocated blocks of segments. Segment is not the
right word to use for it but let's go with it for now. Must have
preallocated blocks of segments of various sizes. Segment of
2 bytes, 4 bytes, 8 bytes, 16 bytes e.t.c up to a maximum limit.
Each segment should have the payload which would be anything ... as long as
it fits the segment size and then at the end a pointer to the next segment
which shall initially be null.

All the recursive data structures should request and add segments from this
memory region. This region should be managed by the runtime with a simple
memory allocation algorithm. Each time that a node is to be added to a data
structure then a segment from the region should be requested. Have to think
what to do about structures which would exceed the size limit. I suppose
fallback to malloc?

In another note I believe I should have a configurable pool of worker
threads in the runtime doing nothing unless the user requests
parallelization in which case he would not have to bother himself with
threading but simply with his algorithm and the work will be separated
 between the worker threads. More thoughts on this to come later.

Functional language and imperative hybrid? Pattern matching is a killer
feature! (But how heavy is its implementation?)
Whether or not functional language constructs are added into the language,
a form of pattern matching can be added since it seems to be quite useful.
Investigate more. For example erlang style bit pattern matching?
http://learnyousomeerlang.com/starting-out-for-real#bit-syntax

For pattern matching (and I suppose general functional language programming implementations look at)
http://research.microsoft.com/en-us/um/people/simonpj/papers/slpj-book-1987/
** Memory allocators
I have been thinking of having a kind of slab memory pool allocator. So to
basically have different memory pools for different sizes of structures
like so:
#+BEGIN_SRC ditaa :file images/slab_memory_pool.png
/--+       +--------------------+
|2 | ----- | 2 byte memory pool | ----+
+--/       +--------------------+     |
/--+       +--------------------+     |
|4 | ----- | 4 byte memory pool | ----+
+--/       +--------------------+     |
/--+       +--------------------+     |
|8 | ----- | 8 byte memory pool | ----+
+--/       +--------------------+     |
                                      |
            ......                    |
/--+       +--------------------+     |
|64 | ---- | 64 byte memory pool| ----+
+--/       +--------------------+     |
                                      |
                             +----------------+
                             | Chunk allocator|
                             +----------------+
#+END_SRC

Another nice addition to this would be a named allocator that would be used
by the language's runtime. What a named allocator means is that the runtime
has a special memory pool for each of the structures/data objects created
by the compiled program. This allows the user to optionally also collect
statistic as to how many instances of a particular object have been
initialized, how many freed e.t.c.

#+BEGIN_SRC ditaa :file images/slab_memory_pool2.png
                       /--+       +--------------------+
                       |2 | ----- | 2 byte memory pool | ----+
                       +--/       +--------------------+     |
/------------------+   /--+       +--------------------+     |
| person allocator |-- |4 | ----- | 4 byte memory pool | ----+
+------------------/   +--/       +--------------------+     |
                       /--+       +--------------------+     |
                       |8 | ----- | 8 byte memory pool | ----+
                       +--/       +--------------------+     |
                                                             |
                                   ......                    |
/------------------+   /---+       +---------------------+   |
| book   allocator |-- |64 | ----- | 64 byte memory pool | --+
+------------------/   +---/       +---------------------+   |
                                                             |
                                                    +----------------+
                                                    | Chunk allocator|
                                                    +----------------+
#+END_SRC

The way that a free list can be kept is like below:

#+BEGIN_SRC C++
struct mem_meta {
    mem_meta *next;
    size_t sz;
    uint8_t buf[]; //flexible array members
};
#+END_SRC

So when you allocate a pointer from the memory pool you will allocate the
whole mem_meta. and return the buf. When the user frees he would free the
buffer and we at the implementation would take the mem_meta * with the
container_of() macro and hene know the size and/or other meta data. With
those data it would be possible to decide which pool to use for freeing
(basically add it to the free list of that pool.

From my talk with Stephen he mentioned some scheme that concurrent allocators
like jmalloc use. There may be (gotta check for the details) a global slab
allocator that allocates different sizes of elements from different memory
pools from a global pool. then threads acquire this big pool with a mutex
and allocate from there. When they free they send the elemnts to a free list,
so that they can be reallcoated later without having to hold the global mutex.

This is a nice scheme but a big disadvantage of it is that if one thread
allocates and another thread frees, like it so often tends to happen,
then there is a bottleneck in the global allocator since the thread-local
free-lists are never used.
* Notes / Thoughts / Resources
** Haskel internal representation
http://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/HeapObjects
http://stackoverflow.com/questions/15063115/internal-representation-of-haskell-lists
http://stackoverflow.com/questions/3254758/memory-footprint-of-haskell-data-types
** Coroutines and continutations
General Continuation implementation:
  http://c2.com/cgi/wiki?ContinuationImplementation

Coroutine implementations in C:
http://www.chiark.greenend.org.uk/~sgtatham/coroutines.html
** Error handling thoughts
http://programmers.stackexchange.com/questions/147059/the-modern-way-to-perform-error-handling
** Algebraic Data types
http://blog.lab49.com/archives/3011
http://stackoverflow.com/questions/16770/haskells-algebraic-data-types

Interestni questions about AlgDT and haskell in SO:
http://stackoverflow.com/questions/9190352/abusing-the-algebra-of-algebraic-data-types-why-does-this-work
** Tail call optimization
I should try and make sure that many things that require recursion and
deal with the ADTs strive for tail recursion and [[http://stackoverflow.com/questions/310974/what-is-tail-call-optimization][tail call optimization]]
